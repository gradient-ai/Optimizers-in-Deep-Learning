{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "# Gradient Descent and Optimization In Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "In this notebook we'll implement gradient descent with and without momentum using PyTorch. We'll also visualize our gradient updates on Ackley's function as movement along the contour plots. Weâ€™ll then discuss and benchmark several optimizers for an image classification task using the CIFAR10 dataset, and train a ResNet18 for this purpose.\n",
    "\n",
    "Optimizers covered include:\n",
    "* Nesterov momentum\n",
    "* Adam\n",
    "* AdaGrad\n",
    "* AdaMax\n",
    "* AdamW\n",
    "* AdaDelta\n",
    "\n",
    "\n",
    "For a more detailed breakdown of the theory behind the code, check out the full tutorial [on the blog](https://blog.paperspace.com/optimization-in-deep-learning/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import RandomSampler, DataLoader\n",
    "\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10 as cifar\n",
    "from torchvision import datasets\n",
    "\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "def gradient(f, X, h):\n",
    "    grad = []\n",
    "    for i in range(len(X)):\n",
    "        Xgplus = np.array([x if not i == j else x + h for j, x in enumerate(X)])\n",
    "        Xgminus = np.array([x if not i == j else x - h for j, x in enumerate(X)])\n",
    "        grad.append(f(*Xgplus) - f(*Xgminus) / (2 * h))\n",
    "    return np.array(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "def vanilla_update(epoch, X, f, lr, h):\n",
    "    grad = gradient(f, X, h)\n",
    "    X1 = np.zeros_like(X)\n",
    "    for i in range(len(X)):\n",
    "        X1[i] = X[i] - lr * grad[i]\n",
    "    print('epoch: ', epoch, 'point: ', X1, 'gradient: ', grad)\n",
    "    return X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "def ackleys_function(x, y):\n",
    "    return - 20 * np.exp(- 0.2 * np.sqrt(0.5 * (x ** 2 + y ** 2))) \\\n",
    "           - np.exp(0.5 * (np.cos(2 * np.pi * x) + np.cos(2 * np.pi * y))) \\\n",
    "           + np.e + 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "h = 1e-3\n",
    "f = ackleys_function\n",
    "point = np.array([-2., -2.])\n",
    "i = 0\n",
    "lr = 0.00001\n",
    "while True:\n",
    "    new_point = vanilla_update(i+1, point, f, lr, h)\n",
    "    if np.sum(abs(new_point - point)) < h:\n",
    "        print('Converged.')\n",
    "        break\n",
    "    point = new_point\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "def momentum_update(epoch, X, f, lr, m, h, vel=[]):\n",
    "    grad = gradient(f, X, h)\n",
    "    X1 = np.zeros_like(X)\n",
    "    for i in range(len(X)):\n",
    "        vel[i] = m * vel[i] + lr * grad[i]\n",
    "        X1[i] = X[i] - vel[i]\n",
    "    print('epoch: ', epoch, 'point: ', X1, 'gradient: ', grad, 'velocity: ', vel)\n",
    "    return X1, vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "def get_scatter_plot(X, Y, function):\n",
    "    Z = function(X, Y)\n",
    "    fig = plt.figure()\n",
    "    cm = plt.cm.get_cmap('viridis')\n",
    "    plt.scatter(X, Y, c=Z, cmap=cm)\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def get_contours(X, Y, function):\n",
    "    Z = function(X, Y)\n",
    "    fig = plt.figure()\n",
    "    contours = plt.contour(X, Y, Z, colors='black',\n",
    "                           linestyles='dashed',\n",
    "                           linewidths=1)\n",
    "    plt.clabel(contours, inline=1, fontsize=10)\n",
    "    plt.contourf(X, Y, Z)\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def get_3d_contours(X, Y, function):\n",
    "    Z = function(X, Y)\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes(projection='3d')\n",
    "    cm = plt.cm.get_cmap('viridis')\n",
    "    ax.contour3D(X, Y, Z, 100, cmap=cm)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_zlabel('z')\n",
    "    plt.show()\n",
    "    return fig\n",
    "    \n",
    "def get_surface_plot(X, Y, function):\n",
    "    Z = function(X, Y)\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes(projection='3d')\n",
    "    cm = plt.cm.get_cmap('viridis')\n",
    "    ax.plot_surface(X, Y, Z, rstride=1,\n",
    "                    cstride=1, cmap=cm)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_zlabel('z')\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1, 1000)\n",
    "X, Y = np.meshgrid(x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "get_scatter_plot(X, Y, ackleys_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "get_contours(X, Y, ackleys_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "get_3d_contours(X, Y, ackleys_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "get_surface_plot(X, Y, ackleys_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-2, 2, 1000)\n",
    "\n",
    "h = 1e-3\n",
    "\n",
    "f = ackleys_function\n",
    "\n",
    "a, b = np.meshgrid(x, x)\n",
    "Z = f(a, b)\n",
    "contours = plt.contour(a, b, Z, colors='black',\n",
    "                       linestyles='dashed',\n",
    "                       linewidths=1)\n",
    "plt.clabel(contours, inline=1, fontsize=10)\n",
    "plt.contourf(a, b, Z)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "\n",
    "point = np.array([-2., -2.])\n",
    "\n",
    "i = 0\n",
    "lr = 0.00001\n",
    "while True:\n",
    "    new_point = vanilla_update(i+1, point, f, lr, h)\n",
    "    plt.plot(*point, 'ro', ms=1)\n",
    "    if np.sum(abs(new_point - point)) < h:\n",
    "        print('Converged.')\n",
    "        break\n",
    "    point = new_point\n",
    "    i += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-2, 2, 1000)\n",
    "\n",
    "h = 1e-3\n",
    "\n",
    "f = ackleys_function\n",
    "\n",
    "a, b = np.meshgrid(x, x)\n",
    "Z = f(a, b)\n",
    "contours = plt.contour(a, b, Z, colors='black',\n",
    "                       linestyles='dashed',\n",
    "                       linewidths=1)\n",
    "plt.clabel(contours, inline=1, fontsize=10)\n",
    "plt.contourf(a, b, Z)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "\n",
    "point = np.array([-2., -2.])\n",
    "vel = np.zeros_like(point)\n",
    "\n",
    "i = 0\n",
    "lr = 0.00001\n",
    "m = 0.1\n",
    "grads = []\n",
    "while True:\n",
    "    new_point, vel = momentum_update(i+1, point, f, lr, m, h, vel=vel)\n",
    "    plt.plot(*point, 'bo', ms=1)\n",
    "    if np.sum(abs(new_point - point)) < h:\n",
    "        print('Converged.')\n",
    "        break\n",
    "    point = new_point\n",
    "    i += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "DATA_PATH = 'cifar'\n",
    "\n",
    "\n",
    "trans = transforms.Compose(\n",
    "            [\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomCrop(32, padding=4),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[n/255. for n in [129.3, 124.1, 112.4]], \n",
    "                    std=[n/255. for n in [68.2,  65.4,  70.4]]\n",
    "                )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "train = cifar(DATA_PATH, train=True, transform=trans, download=True)\n",
    "test = cifar(DATA_PATH, train=False, transform=trans, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_size = len(train)\n",
    "test_size = len(test)\n",
    "\n",
    "train_dataloader = DataLoader(train, shuffle=True, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "class Cifar10_Resnet18(nn.Module):\n",
    "\n",
    "    def __init__(self,):\n",
    "        super(Cifar10_Resnet18, self).__init__()\n",
    "        self.base = models.resnet18(pretrained=True)\n",
    "        self.classification = nn.Linear(in_features=1000, out_features=10)\n",
    "\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        out = self.base(inputs)\n",
    "        out = self.classification(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "device = torch.device(type='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "optimizers = {\n",
    "        'SGD': 'optim.SGD(model.parameters(), lr=0.01, momentum=0.9)',\n",
    "        'Adam': 'optim.Adam(model.parameters())',\n",
    "        'Adadelta': 'optim.Adadelta(model.parameters())',\n",
    "        'Adagrad': 'optim.Adagrad(model.parameters())',\n",
    "        'AdamW': 'optim.AdamW(model.parameters())',\n",
    "        'Adamax': 'optim.Adamax(model.parameters())',\n",
    "        'ASGD': 'optim.ASGD(model.parameters())',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "epochs = 5 # 50 is better, 5 is used for demo purposes\n",
    "\n",
    "optim_keys = list(optimizers.keys())\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "for i, optim_key in enumerate(optim_keys):\n",
    "    print('-------------------------------------------------------')\n",
    "    print('Optimizer:', optim_key)\n",
    "    print('-------------------------------------------------------')\n",
    "    print(\"{:<8} {:<25} {:<25} {:<25} {:<25} {:<25}\".format('Epoch', 'Train Acc', 'Train Loss', 'Val Acc', 'Val Loss', 'Train Time'))\n",
    "    \n",
    "    model = Cifar10_Resnet18()\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = eval(optimizers[optim_key])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    optim_train_acc = []\n",
    "    optim_test_acc = []\n",
    "    optim_train_loss = []\n",
    "    optim_test_loss = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        epoch_loss = []\n",
    "        epoch_accuracy = []\n",
    "        \n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            images, labels = batch\n",
    "            \n",
    "            out = model(images)\n",
    "            \n",
    "            loss = criterion(out, labels)\n",
    "            \n",
    "            confidence, predictions = out.max(dim=1)\n",
    "            truth_values = predictions == labels\n",
    "            acc = truth_values.sum().float().detach().cpu().numpy() / truth_values.shape[0]\n",
    "            \n",
    "            epoch_accuracy.append(acc)\n",
    "            epoch_loss.append(loss.float().detach().cpu().numpy().mean())\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        optim_train_loss.append(np.mean(epoch_loss))\n",
    "        optim_train_acc.append(np.mean(epoch_accuracy))\n",
    "        \n",
    "        test_epoch_loss = []\n",
    "        test_epoch_accuracy = []\n",
    "        \n",
    "        end = time.time()\n",
    "        \n",
    "        model.eval()\n",
    "        for step, batch in enumerate(test_dataloader):\n",
    "            \n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            images, labels = batch\n",
    "            \n",
    "            out = model(images)\n",
    "            \n",
    "            loss = criterion(out, labels)\n",
    "            \n",
    "            confidence, predictions = out.max(dim=1)\n",
    "            truth_values = predictions == labels\n",
    "            acc = truth_values.sum().float().detach().cpu().numpy() / truth_values.shape[0]\n",
    "            \n",
    "            test_epoch_accuracy.append(acc)\n",
    "            test_epoch_loss.append(loss.float().detach().cpu().numpy().mean())\n",
    "        \n",
    "        optim_test_loss.append(np.mean(test_epoch_loss))\n",
    "        optim_test_acc.append(np.mean(test_epoch_accuracy))\n",
    "        \n",
    "        print(\"{:<8} {:<25} {:<25} {:<25} {:<25} {:<25}\".format(epoch+1, \n",
    "                                                                np.mean(epoch_accuracy), \n",
    "                                                                np.mean(epoch_loss), \n",
    "                                                                np.mean(test_epoch_accuracy), \n",
    "                                                                np.mean(test_epoch_loss), \n",
    "                                                                end-start))\n",
    "    \n",
    "    train_losses.append(optim_train_loss)\n",
    "    test_losses.append(optim_test_loss)\n",
    "    train_accuracies.append(optim_train_acc)\n",
    "    test_accuracies.append(optim_train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "train_accuracies = dict(zip(optim_keys, train_accuracies))\n",
    "test_accuracies = dict(zip(optim_keys, test_accuracies))\n",
    "train_losses = dict(zip(optim_keys, train_losses))\n",
    "test_losses = dict(zip(optim_keys, test_losses))\n",
    "\n",
    "with open('train_accuracies', 'wb') as f:\n",
    "    pickle.dump(train_accuracies, f)\n",
    "with open('train_losses', 'wb') as f:\n",
    "    pickle.dump(train_losses, f)\n",
    "with open('test_accuracies', 'wb') as f:\n",
    "    pickle.dump(test_accuracies, f)\n",
    "with open('test_losses', 'wb') as f:\n",
    "    pickle.dump(test_losses, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "x = np.arange(epochs) + 1\n",
    "\n",
    "for optim_key in optim_keys:\n",
    "    plt.plot(x, train_accuracies[optim_key], label=optim_key)\n",
    "\n",
    "plt.title('Training Accuracies')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "for optim_key in optim_keys:\n",
    "    plt.plot(x, train_losses[optim_key], label=optim_key)\n",
    "\n",
    "plt.title('Training Losses')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "for optim_key in optim_keys:\n",
    "    plt.plot(x, test_accuracies[optim_key], label=optim_key)\n",
    "\n",
    "plt.title('Testing Accuracies')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "for optim_key in optim_keys:\n",
    "    plt.plot(x, test_losses[optim_key], label=optim_key)\n",
    "\n",
    "plt.title('Testing Losses')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
